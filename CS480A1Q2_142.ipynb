{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2514d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2, part 1\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch MNIST\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X / 255.0 \n",
    "y = y.astype(int)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "# Convert\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921b88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [np.zeros(784) for _ in range(10)]\n",
    "\n",
    "bias = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aaed794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    \n",
    "    accuracies = []\n",
    "\n",
    "    for e in range(10):  # epochs\n",
    "        \n",
    "        correct_predictions = 0 \n",
    "        \n",
    "        for i in range(len(X_train)):  # samples\n",
    "            x_point = X_train[i]\n",
    "            y_point = y_train[i]\n",
    "            \n",
    "            prediction_scores = [np.dot(w, x_point) + b for w, b in zip(weights, bias)]\n",
    "\n",
    "            y_predicted = np.argmax(np.array(prediction_scores))\n",
    "\n",
    "            if y_predicted == y_point:\n",
    "                correct_predictions += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                weights[y_predicted] -= x_point\n",
    "                bias[y_predicted] -= 1\n",
    "                weights[y_point] += x_point\n",
    "                bias[y_point] += 1\n",
    "\n",
    "        epoch_accuracy = correct_predictions / len(X_train)\n",
    "        accuracies.append(epoch_accuracy)\n",
    "        print(f\"Epoch {e + 1}: Accuracy = {epoch_accuracy:.4f}\") \n",
    "    average_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(f\"\\nAverage Accuracy over {len(accuracies)} epochs: {average_accuracy:.4f}\")\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7269a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 0.8491\n",
      "Epoch 2: Accuracy = 0.8727\n",
      "Epoch 3: Accuracy = 0.8766\n",
      "Epoch 4: Accuracy = 0.8791\n",
      "Epoch 5: Accuracy = 0.8816\n",
      "Epoch 6: Accuracy = 0.8831\n",
      "Epoch 7: Accuracy = 0.8848\n",
      "Epoch 8: Accuracy = 0.8847\n",
      "Epoch 9: Accuracy = 0.8852\n",
      "Epoch 10: Accuracy = 0.8865\n",
      "\n",
      "Average Accuracy over 10 epochs: 0.8783\n"
     ]
    }
   ],
   "source": [
    "accuracies = train(X_train, y_train)\n",
    "\n",
    "#Epoch 1: Accuracy = 0.8491\n",
    "#Epoch 2: Accuracy = 0.8727\n",
    "#Epoch 3: Accuracy = 0.8766\n",
    "#Epoch 4: Accuracy = 0.8791\n",
    "#Epoch 5: Accuracy = 0.8816\n",
    "#Epoch 6: Accuracy = 0.8831\n",
    "#Epoch 7: Accuracy = 0.8848\n",
    "#Epoch 8: Accuracy = 0.8847\n",
    "#Epoch 9: Accuracy = 0.8852\n",
    "#Epoch 10: Accuracy = 0.8865\n",
    "\n",
    "#Average Accuracy over 10 epochs: 0.8783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4f05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        x_point = X_test[i]\n",
    "        prediction_scores = []\n",
    "        \n",
    "        for w, b in zip(weights, bias):\n",
    "            prediction_score = np.dot(w, x_point) + b\n",
    "            prediction_scores.append(prediction_score)\n",
    "\n",
    "        y_predicted = np.argmax(np.array(prediction_scores))\n",
    "        predictions.append(y_predicted)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39313a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8848\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(X_test)\n",
    "accuracy = np.sum(predictions == y_test) / len(y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#Test Accuracy: 0.8848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acfcef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2, part 4\n",
    "\n",
    "weights = [np.zeros(784) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d884b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    \n",
    "    accuracies = []\n",
    "\n",
    "    for e in range(10):  # epochs\n",
    "        \n",
    "        correct_predictions = 0 \n",
    "        \n",
    "        for i in range(len(X_train)):  # samples\n",
    "            x_point = X_train[i]\n",
    "            y_point = y_train[i]\n",
    "\n",
    "            prediction_scores = [np.dot(w, x_point)for w in weights]\n",
    "            y_pred = np.argmax(prediction_scores)\n",
    "\n",
    "            if y_pred == y_point:\n",
    "                correct_predictions += 1\n",
    "            else:\n",
    "                # check hinge\n",
    "                if prediction_scores[y_point] <= prediction_scores[y_pred]:\n",
    "                    # hinge loss update\n",
    "                    weights[y_point] += x_point\n",
    "\n",
    "                    weights[y_pred] -= x_point\n",
    "\n",
    "        epoch_accuracy = correct_predictions / len(X_train)\n",
    "        accuracies.append(epoch_accuracy)\n",
    "        print(f\"Epoch {e + 1}: Accuracy = {epoch_accuracy:.4f}\") \n",
    "    average_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(f\"\\nAverage Accuracy over {len(accuracies)} epochs: {average_accuracy:.4f}\")\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d82280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 0.8453\n",
      "Epoch 2: Accuracy = 0.8701\n",
      "Epoch 3: Accuracy = 0.8752\n",
      "Epoch 4: Accuracy = 0.8774\n",
      "Epoch 5: Accuracy = 0.8784\n",
      "Epoch 6: Accuracy = 0.8804\n",
      "Epoch 7: Accuracy = 0.8800\n",
      "Epoch 8: Accuracy = 0.8825\n",
      "Epoch 9: Accuracy = 0.8832\n",
      "Epoch 10: Accuracy = 0.8841\n",
      "\n",
      "Average Accuracy over 10 epochs: 0.8757\n"
     ]
    }
   ],
   "source": [
    "accuracies = train(X_train, y_train)\n",
    "\n",
    "#Epoch 1: Accuracy = 0.8453\n",
    "#Epoch 2: Accuracy = 0.8701\n",
    "#Epoch 3: Accuracy = 0.8752\n",
    "#Epoch 4: Accuracy = 0.8774\n",
    "#Epoch 5: Accuracy = 0.8784\n",
    "#Epoch 6: Accuracy = 0.8804\n",
    "#Epoch 7: Accuracy = 0.8800\n",
    "#Epoch 8: Accuracy = 0.8825\n",
    "#Epoch 9: Accuracy = 0.8832\n",
    "#Epoch 10: Accuracy = 0.8841\n",
    "\n",
    "#Average Accuracy over 10 epochs: 0.8757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce30bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(X_test)\n",
    "accuracy = np.sum(predictions == y_test) / len(y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Test Accuracy: 0.8202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99543058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
